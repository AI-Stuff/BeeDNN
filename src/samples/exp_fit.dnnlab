DataSource=Exp

Epochs=100
BatchSize=0
Loss=MeanSquaredError
KeepBest=1
ReboostEveryEpochs=-1
ClassBalancingWeightLoss=0
Optimizer=iRPROP-
LearningRate=-1
Decay=-1
Momentum=-1

Engine=BeeDNN
NbLayers=3
Problem=Regression

Layer1.type=Dense
Layer1.hasBias=1
Layer1.inputSize=1
Layer1.outputSize=3
Layer1.weight=
-0.03172 0.7734 0.03293 
Layer1.bias=
-0.8645 -3.024 0.817 

Layer2.type=Tanh

Layer3.type=Dense
Layer3.hasBias=1
Layer3.inputSize=3
Layer3.outputSize=1
Layer3.weight=
-12.35 
45.81 
12.33 
Layer3.bias=
30.1 

Notes=
   Toy fitting sample: - first level is 1 -> 5 dense - 5 activation function - last level is 5 ->1 dense  Goals is to play with optimizers/activations
