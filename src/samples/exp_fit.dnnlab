DataSource=Exp
Epochs=100
BatchSize=0
Loss=MeanSquaredError
KeepBest=1
ReboostEveryEpochs=-1
ClassBalancingWeightLoss=0
Optimizer=iRPROP-
LearningRate=-1
Decay=-1
Momentum=-1

Engine=BeeDNN
NbLayers=3
Problem=Regression

Layer1.type=Dense
Layer1.inSize=1
Layer1.outSize=5
Layer1.hasBias=1
Layer1.weight=
1.445 1.265 -0.5192 -0.09324 1.347 
-3.278 -4.12 1.671 0.8187 -0.9587 

Layer2.type=Relu

Layer3.type=Dense
Layer3.inSize=5
Layer3.outSize=1
Layer3.hasBias=1
Layer3.weight=
7.764 
18.08 
-0.5061 
-0.6588 
3.274 
2.353 

Notes=
Toy fitting sample:
- first level is 1 -> 5 dense
- 5 activation function
- last level is 5 ->1 dense

Goals is to play with optimizers/activations
